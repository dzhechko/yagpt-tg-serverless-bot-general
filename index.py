import asyncio
import json
import os

#–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–ª–µ–≥—Ä–∞–º–º
from telegram import Update, Message, Chat
from telegram.ext import filters, MessageHandler, ApplicationBuilder, CommandHandler, ContextTypes

#–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è YaGPT –∏ Langchain
from yandex_chain import YandexLLM
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# Default settings
default_temperature = 0.6
default_context_window = 8000
model_list = [
    "GPT Lite",
    "GPT Pro"      
]    
default_model_index = 1 #–∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª—å—à—É—é –º–æ–¥–µ–ª—å YandexGPT

# Current settings
current_temperature = default_temperature
current_context_window = default_context_window
current_model_index = default_model_index

HELP_MESSAGE = """–ö–æ–º–∞–Ω–¥—ã:
‚ö™ /new ‚Äì –ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥
‚ö™ /mode ‚Äì –í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å
‚ö™ /settings ‚Äì –ü–æ–∫–∞–∑–∞—Ç—å –∏ –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
‚ö™ /history ‚Äì –ü–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –±–µ—Å–µ–¥—ã
‚ö™ /help ‚Äì –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–¥—Å–∫–∞–∑–∫—É

"""

SETTINGS_MESSAGE = """C—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:
‚ö™ –°—Ç–µ–ø–µ–Ω—å –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ /temperature = {current_temperature}. 
    –î–æ–ø—É—Å—Ç–∏–º—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: –æ—Ç 0 –¥–æ 1
‚ö™ –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ /context = {current_context_window}. 
    –î–æ–ø—É—Å—Ç–∏–º—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: –æ—Ç 1000 –¥–æ 8000
"""

ABOUT_MESSAGE = """

–Ø –±–æ—Ç-–ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ LLM –º–æ–¥–µ–ª–∏.
–ú–æ—è –æ—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ - –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤—Å–µ —Ç–≤–æ–∏ –≤–æ–ø—Ä–æ—Å—ã, –∏ –ø–æ–º–æ–≥–∞—Ç—å –≤ —Ä–µ—à–µ–Ω–∏–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á.

–¢–∏–ø–æ–≤—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ —Ä–∞–±–æ—Ç—ã —Å–æ –º–Ω–æ–π - —ç—Ç–æ —É–∑–Ω–∞–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–ª–∏ —Ä–µ—à–∞—Ç—å –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ :)
–ü–æ—Å—Ç–∞—Ä–∞—é—Å—å –±—ã—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω—ã–º!

–¢—ã –º–æ–∂–µ—à—å –≤—ã–±—Ä–∞—Ç—å LLM-–º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä—É—é —Ö–æ—á–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å (https://cloud.yandex.ru/ru/docs/yandexgpt/concepts/models).
–ú–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å —Ä–∞–∑–º–µ—Ä –µ–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏. 
"""


async def new_dialog_handle(update: Update, context: ContextTypes.DEFAULT_TYPE):
    reply_text = "–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–π –±–µ—Å–µ–¥—ã —É–¥–∞–ª–µ–Ω. –ú–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—â–µ–Ω–∏–µ."
    await context.bot.send_message(chat_id=update.effective_chat.id, text=reply_text)

async def show_chat_modes_handle(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # await register_user_if_not_exists(update, context, update.message.from_user)
    # if await is_previous_message_not_answered_yet(update, context): return

    # user_id = update.message.from_user.id
    # db.set_user_attribute(user_id, "last_interaction", datetime.now())
    global model_list, current_model_index
    current_model = model_list[current_model_index]
    message_local = """
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å {model} (https://cloud.yandex.ru/ru/docs/yandexgpt/concepts/models)
–ß—Ç–æ–±—ã –ø–æ–º–µ–Ω—è—Ç—å –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—ã:
    /model = lite     –¥–ª—è GPT lite
    /model = pro      –¥–ª—è GPT pro
    """
    formatted_message = message_local.format(model=current_model)
    reply_text = formatted_message   
    await context.bot.send_message(chat_id=update.effective_chat.id, text=reply_text)
    # await update.message.reply_text(text, reply_markup=reply_markup, parse_mode=ParseMode.HTML)

async def show_settings_handle(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global current_temperature, current_context_window    
    formatted_message = SETTINGS_MESSAGE.format(current_temperature=current_temperature, current_context_window=current_context_window)
    reply_text = formatted_message    
    await context.bot.send_message(chat_id=update.effective_chat.id, text=reply_text)

async def show_history_handle(update: Update, context: ContextTypes.DEFAULT_TYPE):
    reply_text = "–ò—Å—Ç–æ—Ä–∏—è –±–µ—Å–µ–¥—ã"

    await context.bot.send_message(chat_id=update.effective_chat.id, text=reply_text)

async def show_help_handle(update: Update, context: ContextTypes.DEFAULT_TYPE):
    reply_text = ""
    reply_text += ABOUT_MESSAGE
    await context.bot.send_message(chat_id=update.effective_chat.id, text=reply_text)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    reply_text = """
–ü—Ä–∏–≤–µ—Ç!
–Ø –±–æ—Ç-–ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–æ—Å—Ç—Ä–æ–µ–Ω –Ω–∞ –±–∞–∑–µ GPT-–º–æ–¥–µ–ª–µ–π.
–ú–æ—è –æ—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ - –ø–æ–º–æ—á—å —Ç–µ–±–µ —Å –æ—Ç–≤–µ—Ç–∞–º–∏ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∏ —Å —Ä–µ—à–µ–Ω–∏–µ–º –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á 
–¢–æ–ª—å–∫–æ –Ω–µ –∑–∞–±—É–¥—å –≤—ã—Å—Ç–∞–≤–∏—Ç—å –Ω—É–∂–Ω—É—é —Å—Ç–µ–ø–µ–Ω—å –º–æ–µ–π –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏!
ü§ñ
    """
    reply_text += HELP_MESSAGE

    # await update.message.reply_text(reply_text, parse_mode=ParseMode.HTML)

    await context.bot.send_message(chat_id=update.effective_chat.id, text=reply_text)
    # await show_chat_modes_handle(update, context)

async def set_temperature_handle(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global current_temperature
    message_text = update.message.text
    if message_text.startswith('/temperature = '):
        value = message_text.split('=')[-1].strip()
    elif message_text.startswith('/temperature '):
        value = message_text.split(' ')[-1].strip()
    temperature = float(value)
    if 0 <= temperature <= 1:
        current_temperature = temperature
    message_local = """
    –¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã —Ç–µ–ø–µ—Ä—å = {current_temperature}
    """
    formatted_message = message_local.format(current_temperature=current_temperature)
    reply_text = formatted_message    
    await context.bot.send_message(chat_id=update.effective_chat.id, text=reply_text)

async def set_context_handle(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global current_context_window
    message_text = update.message.text
    if message_text.startswith('/context = '):
        value = message_text.split('=')[-1].strip()
    elif message_text.startswith('/context '):
        value = message_text.split(' ')[-1].strip()
    context = int(value)
    if 1000 <= context <= 8000:
        current_context_window = context
    message_local = """
    –¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ —Ç–µ–ø–µ—Ä—å = {current_context} —Ç–æ–∫–µ–Ω–æ–≤.
    """
    formatted_message = message_local.format(current_context=current_context_window)
    reply_text = formatted_message    
    await context.bot.send_message(chat_id=update.effective_chat.id, text=reply_text)

async def set_model_handle(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global model_list, current_model_index

    message_text = update.message.text
    if '/model = lite' in message_text or '/model lite' in message_text:
        current_model_index = 0
    elif '/model = pro' in message_text or '/model pro' in message_text:
        current_model_index = 1
    
    current_model = model_list[current_model_index]
    message_local = """
    –¢–µ–∫—É—â–∞—è LLM-–º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä—É—é –∏—Å–ø–æ–ª—å–∑—É–µ–º: {current_model}.
    """
    formatted_message = message_local.format(current_model=current_model)
    reply_text = formatted_message    
    await context.bot.send_message(chat_id=update.effective_chat.id, text=reply_text)

async def process_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global current_temperature, current_context_window, current_model_index
    # –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    message_text = update.message.text

    if  message_text == "/start":
        # await context.bot.send_message(chat_id=update.effective_chat.id, text=update.message.text)
        await start(update, context)
    elif message_text == "/new":
        await new_dialog_handle(update, context)
    elif message_text == "/mode":
        await show_chat_modes_handle(update, context)
    elif message_text == "/settings":
        await show_settings_handle(update, context)
    elif message_text == "/history":
        await show_history_handle(update, context)
    elif message_text == "/help":
        await show_help_handle(update, context)
    elif message_text.startswith("/temperature"):
        await set_temperature_handle(update, context)
    elif message_text.startswith("/context"):
        await set_context_handle(update, context)
    elif message_text.startswith("/model"):
        await set_model_handle(update, context)
    else:
        # –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ –º–æ–¥–µ–ª–∏ YaGPT
        yagpt_folder_id = os.environ["YAGPT_FOLDER_ID"]
        yagpt_api_key = os.environ["YAGPT_API_KEY"]
        yagpt_temperature = current_temperature
        yagpt_max_tokens = current_context_window

        # if current_model_index==0: 
            # model_uri = "gpt://"+str(yagpt_folder_id)+"/yandexgpt-lite/latest"
        # else:
            # model_uri = "gpt://"+str(yagpt_folder_id)+"/yandexgpt/latest"    
        # model = ChatYandexGPT(api_key=yagpt_api_key, model_uri=model_uri, temperature = yagpt_temperature)

        yagpt_prompt = """
        –¢–µ–±—è –∑–æ–≤—É—Ç –Ø—à–∞. –¢—ã –æ—á–µ–Ω—å –ø–æ–ª–µ–∑–Ω—ã–π –ò–ò-–ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∫–æ—Ä–æ—Ç–∫–æ –∏ —Ç–æ—á–Ω–æ. –°–ª–µ–¥—É–π –ø–æ–∂–µ–ª–∞–Ω–∏—è–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –¥–æ —Ç–µ—Ö –ø–æ—Ä –ø–æ–∫–∞ –æ–Ω–∏ –Ω–µ –≤—ã—Ö–æ–¥—è—Ç –∑–∞ —Ä–∞–º–∫–∏ —ç—Ç–∏–∫–∏. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç, –≤–µ–∂–ª–∏–≤–æ –Ω–∞–ø–∏—à–∏ –æ–± —ç—Ç–æ–º.
        """
        if current_model_index == 1: bool_lite = False #–∏—Å–ø–æ–ª—å–∑—É–µ–º pro –º–æ–¥–µ–ª—å YandexGPT
        if current_model_index == 0: bool_lite = True  #–∏—Å–ø–æ–ª—å–∑—É–µ–º lite –º–æ–¥–µ–ª—å YandexGPT
        llm = YandexLLM(api_key=yagpt_api_key, folder_id=yagpt_folder_id, temperature = yagpt_temperature, max_tokens=yagpt_max_tokens, use_lite=bool_lite)        
        str2 = """–í–æ–ø—Ä–æ—Å: {question}
        –¢–≤–æ–π –æ—Ç–≤–µ—Ç:"
        """
        template = f"{yagpt_prompt} {str2}"
        prompt = PromptTemplate(template=template, input_variables=["question"])
        llm_chain = LLMChain(prompt=prompt, llm=llm)
        response = llm_chain.run({"question": message_text})
        await context.bot.send_message(chat_id=update.effective_chat.id, text=response)



bot = ApplicationBuilder().token(os.environ["BOT_TOKEN"]).updater(None).build()

bot.add_handler(CommandHandler("start", start))
bot.add_handler(CommandHandler("mode", show_chat_modes_handle))

bot.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), process_text_message))

loop = asyncio.get_event_loop()
loop.run_until_complete(bot.initialize())

async def handler(event, context):
    message = json.loads(event["messages"][0]["details"]["message"]["body"])
    update = Update(
        update_id=message["update_id"],
        message=Message(
            message_id=message["message"]["message_id"],
            date=message["message"]["date"],
            chat=Chat(
                id=message["message"]["chat"]["id"],
                type=message["message"]["chat"]["type"]
            ),
            text=message["message"]["text"],
        )
    )

    await bot.process_update(update)

    return {
        "statusCode": 500,
    }
